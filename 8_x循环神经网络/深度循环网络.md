到目前为止，我们只讨论了具有一个**单向隐藏层**的循环神经网络。

[图9.3.1](https://zh-v2.d2l.ai/chapter_recurrent-modern/deep-rnn.html#fig-deep-rnn)描述了一个具有**𝐿**个隐藏层的深度循环神经网络， 每个隐状态都连续地传递到当前层的下一个时间步和下一层的当前时间步。
**深度循环神经网络结构**：
![[deep-rnn.svg#pic_center| 350]]
假设在时间步𝑡有一个小批量的输入数据 $𝑋_𝑡∈𝑅^{𝑛×𝑑}$ （样本数：𝑛，每个样本中的输入数：𝑑）。 同时，将$𝑙th$隐藏层（𝑙=1,…,𝐿） 的隐状态设为$𝐻_𝑡^{(𝑙)}∈𝑅^{𝑛×ℎ}$（隐藏单元数：ℎ）， 输出层变量设为$𝑂_𝑡∈𝑅^{𝑛×𝑞}$ （输出数：𝑞）。 设置$𝐻_𝑡^{(0)}=𝑋_𝑡$， 第𝑙个隐藏层的隐状态使用激活函数𝜙𝑙，则：
$$H_t^{(l)}=\phi_l(H_t^{l-1}W_{xh}^{(l)} + H_t^{l}W_{hh}^{(l)} + b_h^{(l)})$$
最后，输出层的计算仅基于第𝑙个隐藏层最终的隐状态：
$$O_t = H_t^{(L)}W_{hq} + b_q$$
与多层感知机一样，隐藏层数目𝐿和隐藏单元数目ℎ都是超参数。

**总结：**
- 在深度循环神经网络中，**隐状态的信息被传递到当前层的下一时间步和下一层的当前时间步**。
- 有许多不同风格的深度循环神经网络， 如长短期记忆网络、门控循环单元、或经典循环神经网络。 这些模型在深度学习框架的高级API中都有涵盖。
- 总体而言，深度循环神经网络需要大量的调参（如学习率和修剪） 来确保合适的收敛，模型的初始化也需要谨慎。