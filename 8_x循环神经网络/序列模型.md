如果说卷积神经网络可以有效地处理空间信息， 那么本章的 _循环神经网络_（recurrent neural network，RNN）则可以更好地处理序列信息。循环神经网络通过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出。
许多使用循环网络的例子都是基于**文本数据**的，因此我们将在本章中重点介绍**语言模型**。

实际中很多数据是有**时序结构**的
	比如电影评分，当然文本，视频，音乐也都是连续的序列

#### 统计工具：
在时间t观察到$x_t$， 那么得到$T$各不独立的随机变量$(x_1, ...,x_T)~p(x)$
使用条件概率展开$p(a,b)=p(a)p(b|a) = p(b)p(a|b)$
![[Pasted image 20250425163645.png | 600]]
当然也可以反序

对 条件概率 建模：这里的$f$ 就是对见过的数据建模，也称为**自回归模型** 例如在过去数据上训练一个MLP模型
$$
p(x_t|x_1, ...,x_{t-1})= p(x_t|f(x_1, ...,x_{t-1}))
$$
核心就是怎么算$f$ ；后面的大部分内容将围绕着如何有效估计 𝑃(𝑥𝑡∣𝑥𝑡−1,…,𝑥1)展开。简单地说，它归结为以下两种策略：

**方案A-马尔科夫假设**：假设当前数据只跟 **t** 个过去数据点相关

**方案B-潜变量模型** -- RNN
引入潜变量 $h_t$ 来表示过去信息$h_t=f(x_1,...,x_{t-1})$
	这样$x_t=p(x_t|h_t)$
	相当于有两个模型：一个是根据 h 和 x 算 h‘；一个是根据 x 和 h’ 算 x‘

这两种情况都有一个显而易见的问题：如何生成训练数据？ 一个经典方法是使用历史观测来预测下一个未来观测。一个常见的假设是虽然特定值𝑥𝑡可能会改变， 但是序列本身的动力学不会改变。 这样的假设是合理的，因为新的动力学一定受新的数据影响， 而我们不可能用目前所掌握的数据来预测新的动力学。
因此，整个序列的估计值都将通过以下的方式获得：
$$P(x1, ..., x_T) = \prod_{t=1}^T P(x_t|x_{t-1},...,x_1) $$
离散的对象（如单词）， 而不是连续的数字，则上述的考虑仍然有效。 唯一的差别是，对于离散的对象， 我们需要使用分类器而不是回归模型


#### 一阶马尔可夫模型:
$$P(x1, ..., x_T) = \prod_{t=1}^T P(x_t|x_{t-1})当P(x_1|x_0)=P(x_1) $$
当假设𝑥𝑡仅是离散值时，这样的模型特别棒， 因为在这种情况下，使用动态规划可以沿着马尔可夫链精确地计算结果。 例如，我们可以高效地计算𝑃(𝑥𝑡+1∣𝑥𝑡−1)：
$$
\begin{matrix}
P(x_{t+1}|x_{t-1})=\frac{\sum_{xt} P(x_{t+1}, x_{t}, x_{t-1})}{P(x_{t-1})}
\\
=\frac{\sum_{xt} P(x_{t+1}|x_{t}, x_{t-1})P(x_{t},x_{t-1})}{P(x_{t-1})}
\\
=\sum_{xt} P(x_{t+1}|x_{t})P(x_{t}|x_{t-1})
\end{matrix}$$

利用这一事实，我们只需要考虑过去观察中的一个非常短的历史：
𝑃(𝑥𝑡+1∣𝑥𝑡,𝑥𝑡−1)=𝑃(𝑥𝑡+1∣𝑥𝑡)。
 隐马尔可夫模型中的动态规划超出了本节的范围 ， 而动态规划这些计算工具已经在**控制算法**和**强化学习**算法广泛使用。

#### 因果关系：
在许多情况下，数据存在一个自然的方向，即在时间上是前进的。未来的事件不能影响过去。 因此，如果我们改变𝑥𝑡，可能会影响未来发生的事情𝑥𝑡+1，但不能反过来。 因此，解释𝑃(𝑥𝑡+1∣𝑥𝑡)应该比解释𝑃(𝑥𝑡∣𝑥𝑡+1)更容易。
 
>   总结:
> 	时序模型中,当前数据跟之前观察得到的数据是相关的
> 	自回归模型使用自身过去数据来预测未来
> 	马尔科夫假设
> 	潜变量模型

