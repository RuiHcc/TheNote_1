将样式图片中的样式（风格）迁移到内容图片上，得到合成图片
或者说我们更为熟知的 ‘滤镜’

### 基于CNN的样式迁移
奠基性工作：
![[Pasted image 20250424202707.png]]
CNN每一层是提取的输入的特征，我们用一个预训练的卷积神经网络来抽取特征，其中的模型参数在训练中无须更新。
这个深度卷积神经网络凭借多个层逐级抽取图像的特征，我们可以选择其中某些层的输出作为**内容特征**或**风格特征**。
这里分别来考虑内容和风格，我们优化的目标是，是合成图像相对于内容图像在内容上的损失最小，同时将其与样式图像对比在样式损失上尽可能小。

训练的不是模型参数，而是要生成的图像本身？

接下来，我们通过前向传播（实线箭头方向）计算风格迁移的损失函数，并通过反向传播（虚线箭头方向）迭代模型参数，即不断更新合成图像。 风格迁移常用的损失函数由3部分组成：
1. _内容损失_ 使合成图像与内容图像在内容特征上接近；
2. _风格损失_ 使合成图像与风格图像在风格特征上接近；
3. _全变分损失_ 则有助于减少合成图像中的噪点。
最后，当模型训练结束时，我们输出风格迁移的模型参数，即得到最终的合成图像。
在下面，我们将通过代码来进一步了解风格迁移的技术细节。