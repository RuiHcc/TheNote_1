### 单机多卡并行
一台机器可以装多个GPU
在训练和预测时，我们将一个小批量计算切分到多个GPU上来达到加速的目的

常用的切分方案有：
	***数据并行**
	模型并行
	通道并行（数据+模型并行）

### 数据并行 vs 模型并行
数据并行：将小批量分成n块，每个GPU拿到完整参数计算一块数据的梯度，在完成每个小批量数据的训练之后，梯度在GPU上聚合
	通常性能更好
	不同GPU拷贝同一份模型参数，一般把梯度计算结果合并
	无人车更关注`功耗`
模型并行：将模型分成n块，每个GPU拿到一块模型计算它的前向和方向结果
	通常用于模型达到单GPU放不下

>**总结**
>当一个模型能用单卡计算时，通常使用数据并行拓展到多卡
>模型并行用在超大模型上


![[Pasted image 20250407154031.png | 600]]

一般来说，𝑘个GPU并行**训练过程**如下：
- 在任何一次训练迭代中，给定的随机的小批量样本都将被分成𝑘个部分，并均匀地分配到GPU上；
- 每个GPU根据分配给它的小批量子集，计算模型参数的损失和梯度；
- 将𝑘个GPU中的局部梯度聚合，以获得当前小批量的随机梯度；
- 聚合梯度被重新分发到每个GPU中；
- 每个GPU使用这个小批量随机梯度，来更新它所维护的完整的模型参数集。